{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your very own neural network\n",
    "\n",
    "In this notebook we're going to build a neural network using naught but pure numpy and steel nerves. It's going to be fun, I promise!\n",
    "\n",
    "<img src=\"frankenstein.png\" style=\"width:20%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import tqdm_utils\n",
    "import download_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the preloaded keras datasets and models\n",
    "download_utils.link_all_keras_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Abstract Layer class and hence every layer which we will implement in future must inherit layer and implement forward and backword pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        \"\"\"initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
    "        # A dummy layer does nothing\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input, train):\n",
    "        \"\"\"\n",
    "        Takes input data of shape [batch, input_units], returns output data [batch, output_units]\n",
    "        \"\"\"\n",
    "        # A dummy layer just returns whatever it gets as input.\n",
    "        return input\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
    "        d loss / d layer = input, so you only nee\n",
    "        update your parameters\n",
    "        \"\"\"\n",
    "        # The gradient of a dummy layer is precisely grad_output, but we'll write it more explicitly\n",
    "        num_units = input.shape[1]\n",
    "        \n",
    "        d_layer_d_input = np.eye(num_units)\n",
    "        \n",
    "        return np.dot(grad_output, d_layer_d_input) # chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The road ahead\n",
    "\n",
    "We're going to build a neural network that classifies MNIST digits. To do so, we'll need a few building blocks:\n",
    "- Dense layer - a fully-connected layer, $f(X)=W \\cdot X + \\vec{b}$\n",
    "- ReLU layer (or any other nonlinearity you want)\n",
    "- Loss function - crossentropy\n",
    "- Backprop algorithm - a stochastic gradient descent with backpropageted gradients\n",
    "\n",
    "Let's approach them one at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinearity layer\n",
    "\n",
    "This is the simplest layer you can get: it simply applies a nonlinearity to each element of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
    "        self.details=\"Activation\"\n",
    "    \n",
    "    def forward(self, input,train=True):\n",
    "        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n",
    "        # <your code. Try np.\n",
    "        mat = input >= 0\n",
    "        return np.multiply(input,mat)\n",
    "    \n",
    "    def backward(self, input, grad_output,debug=False):\n",
    "        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n",
    "        relu_grad = input > 0\n",
    "        return grad_output*relu_grad        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some tests\n",
    "from util import eval_numerical_gradient\n",
    "x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "l = ReLU()\n",
    "grads = l.backward(x,np.ones([10,32])/(32*10))\n",
    "numeric_grads = eval_numerical_gradient(lambda x: l.forward(x).mean(), x=x)\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0),\\\n",
    "    \"gradient returned by your layer does not match the numerically computed gradient\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer\n",
    "\n",
    "Now let's build something more complicated. Unlike nonlinearity, a dense layer actually has something to learn.\n",
    "\n",
    "A dense layer applies affine transformation. In a vectorized form, it can be described as:\n",
    "$$f(X)= W \\cdot X + \\vec b $$\n",
    "\n",
    "Where \n",
    "* X is an object-feature matrix of shape [batch_size, num_features],\n",
    "* W is a weight matrix [num_features, num_outputs] \n",
    "* and b is a vector of num_outputs biases.\n",
    "\n",
    "Both W and b are initialized during layer creation and updated each time backward is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.1,init=\"xavier\",dropout=0):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        # %age of neurons to keep in each iteration \n",
    "        self.keep_prob=1-dropout\n",
    "        \n",
    "        self.details=\"Dense:in %s,out %s\" %(input_units,output_units)\n",
    "        \n",
    "        if (init == \"xavier\"):\n",
    "            self.weights = np.random.randn(input_units, output_units)*np.sqrt(2/input_units)\n",
    "        else:\n",
    "            self.weights = np.random.randn(input_units, output_units)*0.01\n",
    "        \n",
    "        self.biases = np.zeros(output_units)\n",
    "        \n",
    "        \n",
    "    def forward(self,input,train=True):\n",
    "        w=self.weights\n",
    "        if train:\n",
    "            shape=self.weights.shape\n",
    "            # mask becomes a matrix of 0 and 1 \n",
    "            self.mask=np.random.binomial(1,self.keep_prob,size=shape)\n",
    "            w=np.multiply(self.mask,w)\n",
    "            # to ensure expected value remains the same\n",
    "            w=w/self.keep_prob\n",
    "        \n",
    "        return np.dot(input,w)+self.biases\n",
    "    \n",
    "    def backward(self,input,grad_output,debug=False):\n",
    "        # compute d f / d x = d f / d dense * d dense / d x\n",
    "        # d dense/ d x = weights transposed\n",
    "        # d f / d dense = grad_output\n",
    "        # grad_input = d Loss / d curr_layer  *  d curr_layer / d prev_layer\n",
    "        grad_input = np.dot(grad_output,self.weights.T) \n",
    "        \n",
    "        # compute gradient w.r.t. weights and biases\n",
    "        grad_weights = np.dot(input.T,grad_output)\n",
    "        grad_biases = np.sum(grad_output,axis=0)\n",
    "        if debug:\n",
    "            print(\"w\",self.weights)\n",
    "            print(\"m\",self.mask)\n",
    "            print(\"gdw\",grad_weights)\n",
    "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
    "        \n",
    "        #SGD\n",
    "        #we apply the same mask again which was generated during the fwd pass\n",
    "        #to ensure that we dont update the weights which were off\n",
    "        self.weights = self.weights - self.learning_rate * grad_weights * self.mask\n",
    "        self.biases = self.biases - self.learning_rate * grad_biases\n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loss function\n",
    "\n",
    "Since we want to predict probabilities, it would be logical for us to define softmax nonlinearity on top of our network and compute loss given predicted probabilities. However, there is a better way to do so.\n",
    "\n",
    "If you write down the expression for crossentropy as a function of softmax logits (a), you'll see:\n",
    "\n",
    "$$ loss = - log \\space {e^{a_{correct}} \\over {\\underset i \\sum e^{a_i} } } $$\n",
    "\n",
    "If you take a closer look, ya'll see that it can be rewritten as:\n",
    "\n",
    "$$ loss = - a_{correct} + log {\\underset i \\sum e^{a_i} } $$\n",
    "\n",
    "It's called Log-softmax and it's better than naive log(softmax(a)) in all aspects:\n",
    "* Better numerical stability\n",
    "* Easier to get derivative right\n",
    "* Marginally faster to compute\n",
    "\n",
    "So why not just use log-softmax throughout our computation and never actually bother to estimate probabilities.\n",
    "\n",
    "Here you are! We've defined the both loss functions for you so that you could focus on neural network part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
    "    \n",
    "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    return xentropy\n",
    "\n",
    "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy gradient from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    ones_for_answers = np.zeros_like(logits)\n",
    "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "    \n",
    "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "    \n",
    "    return (- ones_for_answers + softmax) / logits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = np.linspace(-1,1,500).reshape([50,10])\n",
    "answers = np.arange(50)%10\n",
    "\n",
    "softmax_crossentropy_with_logits(logits,answers)\n",
    "grads = grad_softmax_crossentropy_with_logits(logits,answers)\n",
    "numeric_grads = eval_numerical_gradient(lambda l: softmax_crossentropy_with_logits(l,answers).mean(),logits)\n",
    "\n",
    "assert np.allclose(numeric_grads,grads,rtol=1e-3,atol=0), \"The reference implementation has just failed. Someone has just changed the rules of math.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full network\n",
    "\n",
    "Now let's combine what we've just built into a working neural network. As we announced, we're gonna use this monster to classify handwritten digits, so let's get them loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(flatten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define network as a list of layers, each applied on top of previous one. In this setting, computing predictions and training becomes trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network without xavier init\n",
    "network = [\n",
    "    Dense(X_train.shape[1],16),\n",
    "    ReLU(),\n",
    "    Dense(16,32),\n",
    "    ReLU(),\n",
    "    Dense(32,32),\n",
    "    ReLU(),\n",
    "    Dense(32,64),\n",
    "    ReLU(),\n",
    "    Dense(64,128,dropout=0.2),\n",
    "    ReLU(),\n",
    "    Dense(128,10)\n",
    "]\n",
    "\n",
    "# network with xavier init\n",
    "networkX = [\n",
    "    Dense(X_train.shape[1],16,init=\"xavier\"),\n",
    "    ReLU(),\n",
    "    Dense(16,32,init=\"xavier\"),\n",
    "    ReLU(),\n",
    "    Dense(32,32,init=\"xavier\"),\n",
    "    ReLU(),\n",
    "    Dense(32,64,init=\"xavier\"),\n",
    "    ReLU(),\n",
    "    Dense(64,128,init=\"xavier\",dropout=0.2),\n",
    "    ReLU(),\n",
    "    Dense(128,10,init=\"xavier\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(network, X,train=True):\n",
    "    \"\"\"\n",
    "    Compute activations of all network layers by applying them sequentially.\n",
    "    Return a list of activations for each layer. \n",
    "    Make sure last activation corresponds to network logits.\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    input = X\n",
    "\n",
    "    for layer in network:\n",
    "        activations.append(layer.forward(input,train))\n",
    "        input=activations[-1]\n",
    "    \n",
    "    assert len(activations) == len(network)\n",
    "    return activations\n",
    "\n",
    "def predict(network,X):\n",
    "    \"\"\"\n",
    "    Compute network predictions.\n",
    "    \"\"\"\n",
    "    logits = forward(network,X,train=False)[-1]\n",
    "    return logits.argmax(axis=-1)\n",
    "\n",
    "def train(network,X,y,debug=False):\n",
    "    # Get the layer activations\n",
    "    layer_activations = forward(network,X)\n",
    "    layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]\n",
    "    logits = layer_activations[-1]\n",
    "    layer_inputs.pop()\n",
    "    \n",
    "    # Compute the loss and the initial gradient\n",
    "    loss = softmax_crossentropy_with_logits(logits,y)\n",
    "    loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
    "    \n",
    "    grad_input=loss_grad\n",
    "    for layer,input in zip(network[::-1],layer_inputs[::-1]):\n",
    "        grad_input=layer.backward(input,grad_input,debug)\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "As usual, we split data into minibatches, feed each such minibatch into the network and update weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in tqdm_utils.tqdm_notebook_failsafe(range(0, len(inputs) - batchsize + 1, batchsize)):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "train_logX = []\n",
    "val_logX = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Train acc: Net:0.9564 NetX:0.95958\n",
      "Val acc:Net:0.9503 NetX:0.9554\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4VFXewPHvmZn0TCa9kIQUeoDQCaEGBAS7uPYGUtZ1\ndVdXLOCurljXdV3dVd9dC6KiolJcRVRQEgi9CYEQSgIkJISE9Jm0aef9Y0JIqAEmjZzP88wzd+49\n994z50l+9865pwgpJYqiKErHoGntDCiKoigtRwV9RVGUDkQFfUVRlA5EBX1FUZQORAV9RVGUDkQF\nfUVRlA5EBX1FUZQORAV9RVGUDkQFfUVRlA5E19oZOF1gYKCMjo6+5P0rKyvx8vJyXobaMVUWjany\naEyVxylXQlls3769SEoZdKF0bS7oR0dHs23btkvePyUlhaSkJOdlqB1TZdGYKo/GVHmcciWUhRAi\nuynpVPWOoihKB6KCvqIoSgeigr6iKEoH0qSgL4SYJITYL4TIFEI8fZbtUUKIX4QQaUKIFCFERINt\nnYUQK4UQGUKIvUKIaOdlX1EURbkYFwz6Qggt8A4wGYgD7hRCxJ2W7HXgEyllPDAPeKXBtk+Av0sp\newFDgUJnZFxRFEW5eE250x8KZEopD0kpzcAi4MbT0sQBq+uWk09ur7s46KSUqwCklCYpZZVTcq4o\niqJctKYE/XDgaIPPuXXrGtoFTKlbvhnQCyECgO5AmRBiqRDiVyHE3+t+OSiKoiitwFnt9GcDbwsh\npgJrgTzAVnf8UcAAIAf4EpgKfNhwZyHELGAWQEhICCkpKZecEZPJdFn7X0lUWTSmyqMxVR6ntHZZ\nmO1mdlXtwizNjNCPaNZzNSXo5wGRDT5H1K2rJ6U8Rt2dvhDCG7hFSlkmhMgFdkopD9Vt+wYYxmlB\nX0r5HvAewODBg+XldJK4EjpZOIsqi8ZUeTSmyuOU1iqLvcV7WXpwKSsOrcBoMRIfFM/cMXMRQjTb\nOZsS9LcC3YQQMTiC/R3AXQ0TCCECgRIppR2YA8xvsK+vECJISnkCGAdcendbRVGUdq68tpzlh5bz\nTeY37CvZh5vWjfFR45nSdQqDQwc3a8CHJgR9KaVVCPEw8BOgBeZLKdOFEPOAbVLKb4Ek4BUhhMRR\nvfP7un1tQojZwC/C8U22A+83z1dRFEVpm+zSzpbjW1h6cCm/ZP+C2W6ml38vnkl4hmtir8HH1afF\n8tKkOn0p5QpgxWnrnm2wvBhYfI59VwHxl5FHRVGUdul45XG+yfyGbzK/Ic+Uh95Vzy3db2FKtyn0\n9O/ZKnlqcwOuKYqitGcWm4WU3BSWHFzCxmMbsUs7CaEJPDLgEa7qfBXuOvdWzZ8K+oqiKE6QVZbF\n0oNLWX5oOSU1JQR7BjOj7wxu6noTkfrICx+ghaigryiKcokqLZX8ePhHlmYuJe1EGjqNjrGRY7m5\n680M7zQcrabtdUtSQV9RFOUiSCnZeWInSw8u5acjP1FtraaLoQuzB8/m+i7X4+/u39pZPC8V9BVF\nUZqgqLqI77K+Y1nmMg6XH8ZT58nkmMlM6TaF+MD4Zm9q6Swq6CuKopyD1W5lw7ENLD24lDVH12CV\nVvoH9Wfe8HlcHX01ni6eTjmPlJJFW49irLEwa3QXpxzzXFTQVxRFOc3RiqMsy1zG/zL/R2F1If7u\n/twTdw83d72ZWN9Yp54rv7yap5bsZu2BE4zuHsSMkbFoNK3bI1dRFOWKV2OtYVX2KpZlLmPr8a1o\nhIYRnUYwp9scxkSMwUXr4tTzSSlZsiOP579Lx2qTzLuxN/ckRDVrwAcV9BVF6eD2Fu/lq+KvmPvV\nXIwWIxHeETwy4BFu7HIjIV4hzXLOwooa5i7dxfadhxjnJ/lDfx/8MtdRcWwHvrdMufABLoMK+oqi\ndDjlteV8f+h7lmUuY1/JPlyECxNjJtaPf6MRlzeTrLTZsBYXYz1+HMvx41iPF2ApOI4l/zgFWTmY\nco/xh6pyXKQNADNQALj36aOCvqIoijOcb/wbnzwfrhl1TZOOI202rEVFdQG9AOvxfMd7geOz5Xg+\n1sITYLU23tHVlTIvP7K13tgjuhM6pCdBsZG4hIbiEhqKLjQUrZ9fM3zzxlTQVxTlitaU8W9SjqcA\nIK3WBgG98V26Nf84loICrIWFYLM1Oodwc0MXGoJLaBheQ4agCwnFJSzU8R4awppSDXN/ycFYa+PR\nCd2YNSoWnfbyfk1cKhX0FaUFlFWZ2XSohK1HSnDTaYj096SzvyeRfp6E+brj0koB4ErV1PFvrKWl\nlH7xBX7fLefgX5/HeuLEmQHd3R2XkBB0YWF4DR2KLvRkQA85dYfu63vWdvqllWae+Tadb3cdo0+4\nD5/f2p8eofoWKYNzUUFfUZqBscbC1iMlbMgsZuOhYvbmVyAluOk02OwSq13Wp9VqBGEG9/qLQOcA\nTyL8PByf/T0J8HJtNx1/WltTx78x5+ZR8vHHlC1ejKyuhthYvIYNq79bd7w7ql00BsMllf/PewuY\ns2w3pZVmHhvfnYfGdmkTF3cV9BXFCarNNrZll7Axq5gNWcXszivHZpe46jQM6uzHY+O7M7xLAPER\nvmg1gvzyao6WVHO0pIqjpVXklFRxtKSKX/YVUmSqbXRsT1ctkX6OC0Ckv0eji0Oknycerhc3vouU\nklxTLhZpcWYRtJqLGf+mJiOD4g/nU/HDDyAEhmuvxX/6A2w6dox+Tpo5q7zawrzv9rJkRy49Q/V8\nNHUIfcINTjm2M6igr1zxpJTU7N2L9vhxpx2z1mpjZ04ZG7Icd/K/5pRisUl0GkG/SF8eSupCYmwA\nA6P8cHc5MyhH+HkS4edJYpeAM7ZVma3kljouCI6LQTU5JVXkllaxIauIKnPj6odAb7fGFwN/TyLq\nPocZPNBqBLW2Wjbnb2bN0TWsyV1DQVUBGjR0/647vQN6ExcQR+/A3nTz7Yar1tVp5dRczjb+Tawh\nltmDZ3Nd7HUEeAQ0Slu1aRPFH3xI5fr1aDw98b/vPvzvuxeXsDBHomPHnJKvNQdO8NTiNE6Yanl4\nbFf+cFU3XHWtf3ffkAr6yhVJ2mxU79hBxapVGFf9jDU/n0Dg0Gef43PtNfhMnoxrVFSTj2e12UnL\nK2djVjEbs4rZll1CjcWOENA33MADI2JI7BLAkGh/vNwu79/K01VH9xA93UPOrPuVUlJSaXZcDOou\nDCcvDjtySlmelo+trupIaI246vfj5X8Am+t+7KIWnXCnh88grulxN3n5ezC5m/g552eWHFwCgE6j\no7uf40LQO6A3vQN708W3Cy4a53ZMulTF1cV8l/UdSzOXNhr/5uauN9MvqF+jahhptWJcuZLiDz50\nXPQDAwn605/wu+N2tD7OnanKVGvlpe/38sWWo3QN9ua/9w6iX6SvU8/hLCroK1cMabFQuXkLxpUr\nMf7yC7biYoSrK14jR6J/5BH279pFyMGDnHjzLU68+RbucXGOC8CkSbiEhzc6lt0u2ZtfUVddU8TW\nI6WYah1N8HqG6rlzaGcSYwNIiAnA4NlyAVEIQYC3GwHebgzo3Lh5n5SSfSUH+D7zF9bmreGwMQOQ\naPDHwzyMyrIelJZ0ZpPUsQmIMYznpVuHkDg+gGOVx0gvSie92PH68fCPfH3gawBcNa709O9Z/2ug\nd0BvYgwx6DQtEz4udvwbe3U1ZUuXUvLRAiy5ubhGRxP6wjwMN9yAxs3N6fnbkFnEE4vTOFZezW9H\nx/LYhO5n/XXXVqigr7Rr9poaKjdswPjTSozJydgrKhCenniPGY3PxIl4jRqN1tsLgGp/P6Kf/yuW\n/HwqfvyJihUrKPz76xT+/XXc+/WjdtQ4tkcPYG2pYNOhEsqrHXXesUFe3Ni/E8O7BDIs1p8Ab+cH\njktlsVnYVrCNNblrSDmaQp4pD4DeAb35ff+HSIpMoodfj/o7YFOtlaMlVfyaU8brP+zhrg82M7p7\nEE9N6sHE6IlMjJ4IONq05xpzHReBuovBt1nfsmj/IgA8dB709O/ZqGoo2if6sjs1NXSx499YS0sp\n/exzShcuxFZWhke/foQ8/RTe48YhNM6vYqkyW3n1h318sjGbmEAvFj+YyKCotj2sMqigr7RDNlMl\nlalrqVi5EtOatciqKjQGA/px49BPnIDX8OFo3M89JZ1LWBj+U++n4vpbSd+4h4offqDTr+uIevuf\n9EfgFdKFhKGjCbp2MkMGdCXU0LrT252uvLactblrWZO7hvV56zFZTLhp3RgWNowZfWcwOmI0wZ7B\nZ93X201HrzAfeoX5EGjKItslireTM7n2X+u4qX8nHp/Yg0h/TzRCQ2efznT26czkmMmA40KQXZFd\nfyHYW7yXJQeXsDBjIQCeOk96BfRqVDUUqY+8qAvBpYx/Y87NpeSjBZQtWYKsqcF77FgCZkzHY+DA\nZmv1tPVICbO/3kV2cRXTRkTz5NU9L/qBemtRQV9pF2zl5RiTkzGuXEXlunVIsxltQACG669HP2EC\nXglDES5nBoSi6iKWHlzKkgNLKKkqxf+rSKQ5iOJSH8or/LCbAwmMHMKIMTcxxqOKvge20Df5Z8zf\nzYfvF2AelkDp5Mn4TJiA1rf16miPlB8h5WgKKbkp7CzciU3aCPQI5Oroq0mKTCIhLAEPncdFHdNV\nK5g5OpbbhkTynzVZfLT+MN/vzueeYVE8PLbrGb9oNEJDjCGGGEMM18VeB4DNbuNw+eH6aqH04nS+\n3P8ltTZHCyS9i564gDjiAuPqLwbh3uFnBOO9xXtZenApKw6taPL4N9Xp6ZR8OJ+KH38ErRbD9dcT\n8MA03Lp2vahyuBg1Fht//2k/89cfJsLPg0WzhjEs9syH8W2ZCvpKm2UtKsL48y8YV62icvNmsFrR\nhYXhe8ft+EyciMeAAQjtmXdXUkq2FWzjy31f8nPOz9ikDRdzdyorO2NyLULnlg4+ZXjUPcurBtI0\nwVS4RbN7RDRRk26lS4krwRsPYP5lA8f/8izHn5+H14jh+EyejP6qq9Dqm7eDjdVuZWfhTlKOprAm\ndw1HKo4A0MOvB9P7TicpIonegb2dUp1i8HDhqUk9uT8xmrd+OcDHG47w9bZcZo2OZfrImPM+mNZq\ntHT160pXv67c2PVGACx2C4fKDpFe7Pg1kF6UzsK9C7HYHdVlBjdDfbWQwdXA94e/Z1/JPty0boyP\nGn/e8W+klFRu2EDJhx9SuWEjGi8v/KdNxf+++3AJaZ7B0U76NaeUx7/exaETldwzrDNzJve67If2\nraFJORZCTALeArTAB1LKV0/bHgXMB4KAEuAeKWVu3TYbsLsuaY6U8gYn5V25Alny8zGuWkXFypVU\nb98BUuIS1ZmAaVPRT5yIe58+5/zJbjQb+TbzWz5J/4JjVdkIuwe1pYnYyocxvFMY3b3yuXlkX6L9\n3Km115BTmc8RUy7ZlflkV+ZzpOo4PxbtocJa5ThgKOjuFiSUBjI6Q9AjbTOVa9ZyzEWLW/8uBI4Y\ngH5QdzRuLiDtIG2Od3vd++kvuw2Q4BkAhkjwjQR9J9C51ud//bH1pBxNITU3lQpzBTqNjoTQBO7q\ndRdjIsbQybtTs5V9qMGdV6bEM31kDH//aT9vrDrAJxuz+eNVXbljaOcmdyxy0bjQw78HPfx7MKWb\nY/Awi83CwbKDjaqGFuxZgFVa68e/mRwzGYPb2duzS6uVih9/ovjDD6nNyEAXFETw7Mfxvf32Zr8A\n11ptvPnzQf67JotQH3cWTk9gZLfAZj1ncxJSyvMnEEILHAAmALnAVuBOKeXeBmm+BpZLKT8WQowD\npkkp763bZpJSejc1Q4MHD5bbtm27+G9SJyUlhSQndbJozyp+/InDb72JX2QkuuBgXIKD0QUHowsK\ncrwHB6MLCEDoWv9OxXzkiKNp5cpV1Ox23B+4de+OfuJE9BMm4Na923nrZtNPpPPujk9Zf/xnbNSi\nqw6ma0U4d+hcSXQ7Tmh1JhpTfpPyIoEyjYZsFx1HXFzq34+46MjR6ojKFwzPsJO4T+JvArNOkhdt\nxxRrwTushihpJcpiwfsC/1cn5ep0rPELIdnTg+0aC1Ykvlp3Rvv3Jil8DMNjJ+GlD2vSsS7Whf5X\ntmeX8rcf9rHlSAnRAZ7MvroH1/YNc1o9ea2tlpLqEsK8z/397FVVlC1ZSslHH2E5dgzX2FgCpj+A\nz/XXo3F1Xn+Cc5XF7txyHv96JwcKTNw+OJJnruuFj3vbaL56OiHEdinl4Aula8p//FAgU0p5qO7A\ni4Abgb0N0sQBf6pbTga+ubjsKs5U8dNK8h5/HE1gILaSUmr37cdaVAR2e+OEQqANDMAlKPjUhSA4\nGF1wUKMLhdbf36mtH6SU1B44iHHVKowrV1J74AAA7n37EvT4n/CZMAHX6OjzHsNUW8V7mz9nxeGv\nKeAYOrtgpAlmmIrpX5sDbAONDtx7QOxoCOnD3twS4uL6gNCARut4FxoQp5aFRoOf0OAntPQ/ub0u\nrR3J8dpyjlQd50hlPulpGRg2ZRKzq5iYTC3Vru6s6yZ4rZcgt6c/kX6difaOIMqnM1H6SKJ9ogn3\nCiMjfwtrclaTcmIHmTVFAMQiubcGxpYVE19diZYDwDLHl3U3gKEzGCIcvw4MkXXLnR3LXkHQDK1T\nBkX58eVvh5G8v5C//bCfhz//lfciDvH0pJ4M73r5d7puWrdzBnxrSQmlCz+j9LPPsJWX4zFwICF/\nfgbvpKRmaYlzOrPVztvJmbyTnEmgtysfTR3C2J5nfzjunBNWws7PwVINI/7QfOehaUE/HDja4HMu\nkHBaml3AFBxVQDcDeiFEgJSyGHAXQmwDrMCrUkp1QWhGxtXJ5D3+OB7x8WTffx99J00CGozvXXgC\na2HhqdeJQiyFhVgKCqjevRtbcfGZB9Xp0AUG1l8QTv1qaHyhONegU1DXK3bPHkcb+pWrMGdngxB4\nDhpEyNw56MePx6XTOaoupISyHCzH0tiSvppvS7aQ6lqOUSuINlt4ymhiUo0G37C+6LpdCyF9ILQP\nBPUE3amHkYUpKcT1TbrkstUAnepewwGGAbMcVQ9lm9ZT8L8ljExez+j0Ksye5WT0zSGlexbLOpmw\nnzYbklZoGRQyiCcippEUmURnn86ODXY7VBZC2VEoz4Hy3Lrlulf2Bqgtb5wxrRsYwusuBpH1Fwbp\nHYbdLQi71hd7rRV7VRWyugp7VRX2mlpcMzOp9vND4+OD1scHrV6POO3uWQjBuJ4hjOkezLJf83hj\n5f5GzTx7d3Lu8ALmnByKP/qI8qXLkLW1eI+/ioAHpuM5cIBTz3M+GfkVPP7VLvbmVzBlQDjPXd+7\n+fpiGAtgy3uw7UOoLoXYsTD8EWjGsZaaUr3zG2CSlHJG3ed7gQQp5cMN0nQC3gZigLXALUAfKWWZ\nECJcSpknhIgFVgNXSSmzTjvHLGAWQEhIyKBFixZd8hcymUx4eze5NumK4rp3L77v/h/W8HAOPXwf\n62p2EOsdS5RrFF5ar6YdxGpFU1GBprwcbVk5mvIyNGXlaMtPW66sPGNXqdNhNxiwGQzYDQbsvgZs\nBl80FeW4/7oTbWkpUqPB3LMHtQMGUNuvH/bTekZqbLV4VebgbTqMV+URvIyHcTEdYbO75EsfbzZ6\neKCVkv7VHoykCwP8B2A2xFLrFnjBf5QW+duwWnHNyMB923bcdu1CU1ODzduLon7dyOobyoHOOoLc\nQohzj8NTW9epSEowm9HU1iLO9aqpezfXoq02oasqR1tlRFNTiaamGk1tLZgtYLYhLRK7VSDtFx84\npKsrdk9PpKeH493Ds9Fni7sH6dXurC9zoVjjQWyYF0k9Dfj7eyHd3S85WOmys/H6aSVuv/4KWi3V\nCQlUTRiPLTT0ko53sUwmEx6eXnx/2ML/Mi14ucDU3m4MDGme6k/Pyhwij/6PkIIUhLRRFJjA0cib\nqDD0uuRjjh07tknVO00J+onAX6WUV9d9ngMgpXzlHOm9gX1SyoizbFuAo+5/8bnOp+r0L03l5i0c\nnTUL15gYOs1/n2kbHmFP8Z767dE+0cQHxdMvqB/xQfF09e16WT0q7bW1WE+c/qvB8dlSWFj/i8Ju\nNJ7qFTtxAvqkJEfTRynBVADH98DxNCjY41guPuh46Ank6jx53yuUlXowuVjxknrGdLqeR4ZNI8Ln\n4oNBS/9t2GtrqUxNpWLFCozJKcjqarRBgegCAh1323UvWV3tKI8mEp6eaBq+PDxO++yG0NrQCDMa\nqtHISjS2cjSWUjSWIjS1JxCYsdpdkVFXY48ch82ixW6swFZegc1Ygb2iAluFEVvFyeUK7Ebj+TOm\n0aDV69EYDGj1erQGHzR6x68IjY8erY8BrY/+1C8LHx+sJSWULPiYqs2b0ej1+N1xB3733oNLcDNW\npZzFZ8tX8+URV9Jyy7kuPox5N/bB38vJYxBJCYfXwsa34eBK0HlA/7sg8fcQ0OWyD+/MOv2tQDch\nRAyQB9wB3HXayQKBEimlHZiDoyUPQgg/oEpKWVuXZgTw2kV9E+WCqnbs4OjvfodLZASd53/I+zlf\nsqd4D/cE3MPYQWNJK0pjV+Eu1uWt49usbwFHj8o+gX2ID4wnPsjxCvRoej2txs0N14gIXCPOuLY3\nYq+qAmlDY8qB47th899PBfiqolPpfCIo8OzODr8hfGGS7NXnY9EfAmGll2EIM/rdzbioMS3W9d8Z\nNG5u6MePRz9+PPaqKkxr1mBc9TP22tozg7WXJ6JR8Paqe28c0IW7++XXadvtULSf/KVzCSv8DvYv\nh/53wuRHzxt8pM2GvbKy0YWgpKCYlZszyTiYh6+thiGBLvT0BlFpwl5egaWgEFtFOfYKI7K29qzH\n1YWEEPzkk/jedivaFvqVXlFjIT2vgt15ZaTllvPjnmr07lbeuWsg18Y7+cG5zQLpy2DDvx03OF5B\nMPYZGDwdvFq+jf8F/4OklFYhxMPATziabM6XUqYLIeYB26SU3wJJwCtCCImjeuf3dbv3Av4rhLDj\nqBJ9tWGrH+XyVaelcXTmLFyCg4n66CMybHn8N+2/XBd7HQm2BIaGDWVo2FDg1JC6aSfS6l8fp3+M\nVTrGlAn3Dic+MJ5+wf2ID4ynp3/Ps/aAbDK7Hc3aF2DrB2AzO9Zp3SC4F/SYRLV/HFurO7E415cf\nj5QgLdvwCNiCNBTipfPhzm73cnvP207Vd7djGk9PfCZPxmfy5NbOiuOhb3Av9vf8I2G3vwkb/gU7\nPoVfF0LvKTDqcQiJO2M3odXW36Gf5AVMvxEyC028/tN+Pkg/TqC3G3+89cxmnvba2vqLxckLB4BX\nYuIZzxKcyVhjIf1YBbtzy9md53gdLjpVPRnu60FimI43po4hSO/EITZqymHHJ7Dp/6AiDwK7w/X/\ngvjbwaX1enlfsHqnpanqnaarycgg+/6paH18iFr4KZYAH25bfhu1tlqW3LCEHRt2XLAsaqw1ZJRk\nkHYijV0ndpF2Io2CqgLAMdBWr4Be9b8E+gX2I9QrtGlN9ux2+P4x2L4A4u+AruMhtA8lHlGs2lfE\nD3uOsz6zCJtLDoaQrUjPndgwEx/Ujzt63M7E6Im4aZ07xk1H+ttoikblYTwOG9+BbfPBbIIe1zqC\nf8SgizrmjpxSXv1hH1sOn2rmeU2fMDSalpkExlRrJT3vVHDfnVvOoQYBvpPBnT7hBuIjDPQJN9A3\n3ECAt5tz/zbKcx2BfvvHYDZC9CjHw9muE5qlldVJzqzeUdqgmgMHyJn2ABovLzovWIBLaCh/2/Qi\n2RXZfDjxQ3xcmzZ0rLvOnQHBAxgQfKp1xPHK4+wu2l1/Ifhq/1d8uvdTAII9gusvAvFB8cQFxJ3Z\n/d9uh+V/dNzljHqcE0Oe5Ke9BfzwbT6bDqVgk7UEh2XQKW4LJdYsXHQeXBt7A7f3uL1+zlKlhelD\nYeILMPIx2Pxf2Pwf2P89xCbBqNkQPbJJD2kHdvbjy1nDSNl/gr/9uI+HP/+V+IhDPDWpJyOc0Myz\nocpaK+nHKkjLLWNPXZA/VFRZ/3gkrC7A3zwgnD4RjgAf2JyD5R3b6aivT1/mqL/vfTMMfxg6tVzL\no6ZQQb8dqj18mJwHpiNcXIha8BGuEeGsy1vHl/u/5L64++qrcy5VqFcooV6hTIiaADh6Ux4oPeD4\nJVDkqBb6OednwNH0sLtf9/oHxP0C+hK55nXEr59iHzmb5ypuYuErvyAldA4xMWjADnLMa6m0mujk\n1YXf9pjD9V2uR+/auvOGKnU8/WHsHEew2jYfNrwNH18HkQmOO/9uEy8Y/IUQjO0ZzOjuQXzzax5v\nrDrA3R9sZlS3QJ6a1POSZpGqrLWyN79xFU3WCVN9gA/1cQT4G/uH0zfccRfv1Kqac7HbIfNn2Phv\nx0NaV29IeBASfuvoR9EGqaDfzpiPHiVn6jSQks6ffIxrVBRlNWU8u/5Zuvp25Q8Dnd+xw0Xr4hhH\nPbA3d9U9wy+pKWn0bKDhsLu+Nht9eyaQc8xKxpFfGDtQT7V7KntKtmOs0TGh8wRu63Ebg0IGqblf\n2yo3PYz4Iwyd5ajrX/8WfH4bhPZ1BP9eNzg6rZ2HViO4ZVAE18aHsXBTNm8nZ3Ldv9dxY/9OPD6h\nB50DPM+6X5XZyt5jFfXVM7vzyslsEOBDfNzoG27guviw+mqaYH0L15FbamD3V44qsRP7HMNpTJgH\nA+8Hj7Y5ecpJKui3I5Zjx8i5fyqypobOn3yCW2wsUkrmbZpHaW0p745/1+n14Ofi7+5PUmQSSZFJ\nANisFrK+nUna4ZXs7DyYnyprqRFL8YyCrVUQJsL4w4A/cHO3my+qlZDSylw8YOhMGDQV0r6CdW/A\n11MhoJujKij+NrjAw353Fy0zRjlG8/zvmiw+XHeYFbvzuTshihmjYiioqGF3bjlpeeXsySsns9DE\nyXnjg/RuxIcbuKavI8D3DTcQ7NOKQ11XlcDWDx0dqioLHRfBm99zVOXo2v40k6CCfrthKSgke+o0\nbEYjnRd8hHuP7gAsP7ScVdmr+OPAP7Zefbjdjnb5o3RPW0bUiCf4MmscRdmlPHdDDN06lyIQJIQl\nNJqgWmkS3L8jAAAgAElEQVRntC4w4G7odwdkfAtr/wH/ewhSXnUMGzDgHscF4jx83F144uqe3JcY\nzZs/H+TTTdks2HCkfnugtxvxEQYm9QkjPtxA3wgDIa0Z4BsqOQQb33X86rFWOxomDH8EYsY0a+/Z\n5qCCfjtgLSoiZ9o0bEVFdP5oPh69ewOQb8rn5c0vMyB4ANN6T2udzNlt8O0jsPMzqhJnc2vGGA4U\nlPHvOwdwXXzzjQiptBKN1nFXG3eTo4PR2tdhxWxY85rjOcDgBxxVQ+cR4uPOK1P6MmNUDD/vLSAm\n0Iv4CF9CfNzaXnXf0S2OJq0Zyx1jOcXf7uhMdZYmre2FCvptnLW0lJxpD2DJz6fz++/h0a8f4JjF\n6M/r/4xd2nlp5Eutcxdtt8H/fg+7vsA4bDY37RlFbqmJ9+4bzNgeLdujUmlhQkD3qx0Pdo+sg9TX\nYdWzkPoGDPud41mA5/mnDuwS5E2XMW1wyBS7DfZ97+hMlbsF3H1h1J8c30nfMsNCNCcV9NswW0UF\nOdOnY87JIfK//8Fz8KkmuAv3LmTL8S3MGz6PSH1ky2fOboNvHoK0RZQOnc11O0dQXl3LJw8MJaGd\nzSSkXAYhIGaU45W7HVL/ASmvOALm4Acg8WHQN+/kJk5zcqTLje9A6WHwjYLJr0H/u8GtDV6cLpEK\n+m2UzWQiZ+ZMzAcziXj3HbyGDavfdrD0IG/teIuxkWO5qetNLZ+5BgG/cMhsrtmRiF3a+GLmMPpG\nOHfURaUdiRgEd34OBemOO/6Nbzva/A+819ESqC01YZTS0WPWVAiVhUQf/gw2T3WMdBk+GMb/FXpd\nf8EWSu2RCvptkL2qiqO/fZCa9L1EvPUm3qNG1W8z28zMSZ2Dt6s3zyU+1/J1oHYbfPM7SPuSYwNn\nM2nrUDxdBQtnJNA1WLW1V4CQ3vCbD2HsXFj/pqNn6vYFjvrwkY9BYLfmOa+Ujt7EpsK6VwFUnnC8\nn23dyaFBgCgE9LzW8XA2MqHdPZy9GCrotzH2mhqOPvR7qn/9lfA3/oH+qqsabX9357vsL93Pv8b+\niwCPFq5GsVnhmwdh99dk93+cyduGEKR3ZeH0BCL9z97mWunAArrADf+GMU85qnu2f+yoPom70dHW\nPyy+accxVzmaRzYlmFuqztxfaByDnHkFg3cwBPVwvHuH1K/bdKCQxEm3Ovf7t1Eq6LchdrOZ3Ef+\nQNXmzXT626v41E2ActKOgh3M3zOfW7rdwtjOY1s2czYrLPst7FnMwT5/4tqtQ4gJ9OTT6UNbt920\n0vYZImDy3xzDOWx61zEA395voNvVMGSGY27hk8G7svC0YF7oGL/mbDwD6gJ3kOPu3Du4QTAPcrx7\nhzgeKF+gmqY2J8X537uNUkG/jZAWC3mPPkZlaiphL76A4YbG88dXWiqZu24u4d7hPDHkiZbNnM0K\ny2bBniXs6fUoN+4YQt9wHxZMG4KvZ/vokKK0Ad5BMP45R/3+lvcdF4CDPzVO4+57KnCH9asL3GcJ\n5l6BF+wUppydCvptgLRayXviSUyrVxPy7F/w/c1vzkjz2tbXyK/MZ8GkBXi5NHEWLGdoEPC3d3+U\nW34dyvAu/rx332C83dSfj3IJPHxhzBOQ+BDkbHJ8Pln1omuZHuUdmfqvbWXSZuPYnLkYf/yR4Kef\nwv+uu85IszpnNUsPLmVG3xmNRsNsdjYrLJ0J6UvZEPtH7kobyvheIbx91wDcXa68Vg1KC3P1gq5X\nXTid4lTNP628ck7Sbif/ueeo+O47gh57jICpU89IU1RdxPMbn6enf08e6vdQy2XOZoEl0yF9Kb9E\nPsJdexO4qX8n/u+egSrgK0o7pu70W4mUkoIXX6R88RICH3qIwN/OOmua5zc8j8ls4sOJH17eLFYX\n42TA3/s/vg/7Pb8/mMi9w6J4/obeLTYZhqIozUMF/VYgpaTw1b9R+vkXBMyYTuAjD5813dKDS0nJ\nTeHJIU/S1a9ry2TOZoHFD0DGtywNeog/HR7B78d2YfbEHm1vXBRFUS6aCvotTErJiX++ScnHH+N3\n770EPf74WYPp0Yqj/G3r30gITeDuXne3TOYaBPwv/B5kztGRPD25Jw+OOfdk2YqitC8q6Lewov/7\nP4rfew/f224jZO6cswZ8m93G3HVz0QkdL458EY1ogUcvNgssngYZ37HA57c8f3w0L9/cl7sS2lDX\neUVRLpsK+i2o+IMPKPrXvzHcdBOhfz33EAofpX/EzhM7eWXUK4R6tcCoflazI+DvW857nrN4rSiJ\nN2/vx439w5v/3IqitCgV9FtIySefUvj6P/C55hrCXnoRoTn73XtGcQbv/PoOV0dfzbUx1zZ/xhoE\n/LfdZvLvinH8996BXNWrnYyMqCjKRVFBvwWULvqSgpdfRj9hPJ3+9ipCe/Ymj7W2WuakzsHP3Y+/\nDPtL8z84tZodU9/t/55/uszgg+rxLJg2hMQuamhkRblSNamyWAgxSQixXwiRKYR4+izbo4QQvwgh\n0oQQKUKIiNO2+wghcoUQbzsr4+1F2bJvOP7Xv+I9Zgzh//gHwuXczS7f2vEWWeVZvDDiBQxuzTxE\nsdUMX98P+7/nNc0MPrZdzeczh6mAryhXuAsGfSGEFngHmAzEAXcKIU6fK+x14BMpZTwwD3jltO0v\nAGsvP7vtS/ny78l/5hm8hicS/q+3EK7nHqdmU/4mPt37KXf2vJMR4SOaN2PWWvjqPti/gpfFDBZr\nJ/PVbxPpF+nbvOdVFKXVNeVOfyiQKaU8JKU0A4uAG09LEwesrltObrhdCDEICAFWXn5224+KlSs5\n9tRTeA4cSMQ776BxO/eYIhXmCv687s9E+0Tz2KDHmjdjJwP+gR+YZ5/Ojx7XsfjB4XQPUWPhK0pH\nIKSU508gxG+ASVLKGXWf7wUSpJQPN0jzObBZSvmWEGIKsAQIBEpxXAzuAcYDgxvu12D/WcAsgJCQ\nkEGLFi265C9kMpnw9m7dqc1c03bj+9//YomKouwPjyDdzz/08MdFH7Ojcgd/Cv0TUW5RTsvH6WUh\n7Bb67HmVgJJt/MX6AKvdJzB7sDt+7h1jNI628LfRlqjyOOVKKIuxY8dul1IOvlA6Zz3InQ28LYSY\niqMaJw+wAQ8BK6SUued7KCmlfA94D2Dw4MEyKSnpkjOSkpLC5ex/uWqzsjj8yB9w69WLHh/NR6s/\n/x30j0d+ZFv2Nh7q/xD397vfqXlpVBaWGvjqXijZxp+t00kLncLyaUPx8+o4QyO39t9GW6PK45SO\nVBZNCfp5QMOZtyPq1tWTUh4DpgAIIbyBW6SUZUKIRGCUEOIhwBtwFUKYpJRnPAy+UlR8vwJpsxHx\n7jsXDPgFlQW8sPEF+gb2ZWbfmc2XKUsNfHkPZK5irmU6WZ1v5bP7B6N3V+ORK0pH05SgvxXoJoSI\nwRHs7wAajf8rhAgESqSUdmAOMB9ASnl3gzRTcVTvXLEBH8CYkoxH//64BAefN52Ukmc3PIvFbuHl\nkS+j0zRT61lLDXx5N2T+zNOWGZzodgcf361GylSUjuqClblSSivwMPATkAF8JaVMF0LME0KcnN4p\nCdgvhDiA46HtS82U3zbNkp9P7d4M9OMuPJXhov2L2HBsA7MHzybaEN0s+dHYzMi6gP+UZSZVfe7h\nP/cOUgFfUTqwJt1eSilXACtOW/dsg+XFwOILHGMBsOCic9iOmFJSAPAeN+686Q6VH+KNbW8wMnwk\nt3ZvpsmYLdX03vMysnQnT1lm4jL4fv55Yx+0amhkRenQVI9cJzKuTsYlqjOuMTHnTGOxW5ibOhc3\nnRvzhs9rnl63lcXYF92JX13ADxg5nacmqaGRFUVRQd9p7JWVVG3ahN/dd583uL6f9j7pxem8kfQG\nQZ5Bzs9IcRb2hbdiK83hUfMj9J54Pw8ltdBY/IqitHkq6DuJaf16pMWC99hz1+ennUjjvbT3uKHL\nDUyImuD8TORsxv7FHZhqrDxgfoY+vfqogK8oSiMq6DuJaXUyGoMBz4Fnn7i8ylLF3HVzCfYM5umh\nzdCAac9S5LIHybMHMN36JE/ecw26wgznn0dRlHatY3TFbGbSZsO0Zg3eo0efc0C1N7a/QU5FDi+N\nfAm9qxOHPJAS1r0Ji6exyxbDvbzIqzNvYnycGhpZUZQzqTt9J6jetQtbaSn6sUln3Z6am8qX+7/k\n/rj7GRI6xHkntllhxWzY/hHf24fzD88/8uH0kXQJat/dyRVFaT4q6DuBKTkZdDq8Ro06Y1tpTSnP\nbniWrr5deWTgI847aa3RMRZ+5s+8a7uRFYHTWfRAAsH684/zoyhKx6aCvhMYVyfjOWTwGcMuSCl5\nYdMLlNWW8Z/x/8FNe+6RNi9KeR7y89uQBRnMtcwgN+Y2vrhnoBpWQVGUC1J1+pfJnJ2NOSsL/dgz\nO2QtP7ScVdmreGTAI/Tw7+GcEx7fjfxgPLUnDjHVPJva+HuZP3WICviKojSJutO/TMbkZAC8Txt6\n4ZjpGC9vfpmBwQO5P85Jo2ce/Bn59f2U2jy4q/pZkkaP5cmre6BRvWwVRWkiFfQvk2l1Mm7duuEa\ncWqGSLu088y6Z7BLOy+NfAmtxglj3Wz7CPn94xzWRnFX1Z948LqRTB1x7p6/iqIoZ6Oqdy6Drbyc\nqu3bzxhr59O9n7KtYBtPD32aCH3EOfZuIrsdVj0Hyx9li6Y/t9T8hWfvGq8CvqIol0Td6V8G09pU\nsNkaNdU8WnGUt3a8xbjIcdzU9abLO4GlBr55ENKXsUQzkRdt0/jPAwkkxKrJyxVFuTQq6F8GU3Iy\n2oAA3OPj69etzF6JxW5hTsKcyxvgrLIYFt0FRzfxD3kPi3U38+X0BDWXraIol0UF/UskzWZMqano\nJ05AaE7VkqXmpdLTvyehXqGXfvDiLPjsN9jKcnnU+kcOBIxn6QNDCDN4OCHniqJ0ZKpO/xJVbd+O\n3WhE36A+32g2srNwJyPDR176gXM2IT8YT7WxhFur51IYOZmvHkxUAV9RFKdQQf8SGZOTEW5ueCUm\n1q/blL8Jm7RdetDfswT58Q2U2L242vQcYX3G8PEDQzF4qDb4iqI4hwr6l0BKiWl1Ml7DhqHx9Kxf\nn5qbit5FT7+gfhd7QFj3T1j8AFmu3bmq/M9cNTyBf985QE1tqCiKU6k6/UtgzszEkptLwMyZ9euk\nlKzPW09ip8SLm+TcZoUVj8P2Bax3H8MDpdN4/Jp4Zo6KVTNdKYridCroXwLj6rpeuElJ9esOlB6g\nsLqQURFnDrp2TjUVjkHTsn7hC7dbec54E6/dPoCbBoQ7N8OKoih1VNC/BKbVq3Hv0weXkOD6dal5\nqQBNr88vz4PPb0MWZvCK7nd8XjOW+VMHMbJbYHNkWVEUBVBB/6JZi4qoTksj8JGHG61PzU2ll38v\nAj2aELTz0+Dz27DVGHlIPs0OMZAvfzuE3p0MzZRrRVEUhyY9yBVCTBJC7BdCZAohzpjrTwgRJYT4\nRQiRJoRIEUJENFi/QwixUwiRLoR40NlfoKWZ1qwBKdE3mAu3wlzBrhO7mnaXf3AVfDSZaqvkpuq/\ncFA/lKW/G64CvqIoLeKCQV8IoQXeASYDccCdQoi405K9DnwipYwH5gGv1K3PBxKllP2BBOBpIUQn\nZ2W+NRiTk9GFheHWs2f9uo3HNmKTtgvX52+bD5/fTrFbOEllf8GlU1+WPDicSH/P8++nKIriJE25\n0x8KZEopD0kpzcAi4MbT0sQBq+uWk09ul1KapZS1devdmni+NsteU0Pl+g3oxyY1almzLm8delc9\nfQP7nmNHO6x6FpY/RqYhgdEnnqRvz558NmMYfl6uLZR7RVGUptXphwNHG3zOxXHX3tAuYArwFnAz\noBdCBEgpi4UQkcD3QFfgCSnlsdNPIISYBcwCCAkJISUl5WK/Rz2TyXRZ+5+P6+7d+FVXcyggkH11\n57BLO6vzVtPNrRvr1q47Yx+NrZae+94i+MR6fnabwG+P38eoSDfujDSyeUNqs+TzpOYsi/ZIlUdj\nqjxO6Uhl4awHubOBt4UQU4G1QB5gA5BSHgXi66p1vhFCLJZSFjTcWUr5HvAewODBg2VSg6aQFysl\nJYXL2f988pNTqPD0ZNjMGWhcHXfoGcUZVORUMGXAFJK6nnbeymJYdCec2MwXhpnMKUji8Qk9eHhc\n1xZpg9+cZdEeqfJoTJXHKR2pLJoS9POAyAafI+rW1au7e58CIITwBm6RUpadnkYIsQcYBSy+nEy3\nBiklpuRkvEaOrA/44KjaARgRPqLxDnWDpsmKY7zi/TQfnujHa7/py22DI1EURWktTalj3wp0E0LE\nCCFcgTuAbxsmEEIECiFOHmsOML9ufYQQwqNu2Q8YCex3VuZbUk36XqyFhWdMi5ial0pcQFzjpprZ\nG+GDq7BVlfGg5jk+LR/AB/cPVgFfUZRWd8GgL6W0Ag8DPwEZwFdSynQhxDwhxA11yZKA/UKIA0AI\n8FLd+l7AZiHELmAN8LqUcreTv0OLMK1eDRoN3mPG1K8rry0/s6nmsV/hkxupcfHjptrn2WbrxqJZ\nwxjbI/gsR1UURWlZTarTl1KuAFactu7ZBsuLOUuVjZRyFRB/+vr2yJiSjMeAAej8/OrXbczfiF3a\nGRVe11RTSvjpGWp13iSVPo2bTzBLpg0lOtCrlXKtKIrSWLtuQtlSLPn51O7NaDQtIjh64RrcDKea\nah74EbLX86LpBoJDwlnyu+Eq4CuK0qaoYRiawJhcN8BagwlT7NLO+rz1DA8bjlajdYyWueo5jrtE\nsIKJpMxIQO+uxsFXFKVtUXf6TWBKTsE1KgrXmJj6dRklGRTXFJ/qhbtzIRTt57mqW7kjMVYFfEVR\n2iQV9C/AZqqkatMmvMeObdwLN9fRVHN4p+FQa4Lkl8n2iieZodyfGN1KuVUURTk/FfQvoHLDeqTF\nckZTzXV56+gd0JsAjwDY+A6YCni64lZu6B9OsI97K+VWURTl/FTQvwDT6mQ0BgOeAwfWryuvLSet\nKM1RtWMqhPVvkRl4FRstXZgxKuY8R1MURWldKuifh7TZMK1Zg/fo0QjdqWfeG45twC7tjvb5Ka8g\nbbU8WXYTo7oF0jPUpxVzrCiKcn4q6J9H9a5d2EpL0Z+lasfXzZc+0hW2f0xW59vYYQpgxqjYVsqp\noihK06igfx6m1atBp8Nr5Kket3ZpZ13eOoZ3Go529YtIF0+eKZlMjxA9o9VUh4qitHEq6J+HMTkF\nr6FD0Or19esyijMoqSlhpFso7FtOdq+ZbC7UMn1UTIuMnKkoinI5VNA/B3N2NuasLLyTzhxgTSAY\nsfs70IfxYvFYAr3duLF/u54QTFGUDkIF/XM41Qv3zKDfxysc/9zt5A96nJ8zjdyfGIWbTtsa2VQU\nRbkoKuifg2l1Mm7du+MaEVG/rqymjN0ndjOyOA+C43jzxCDcXTTcMyyqFXOqKIrSdCron4WtvJyq\n7dvxHtv4Ln/DsQ1IJKOK8ykb+WeW7SzgN4Mi1Dy3iqK0Gyron4VpbSrYbGc01UzNWY2fXdI7PIEP\n87tgsdt5YITqjKUoSvuhgv5ZmJJXow0MxL1v3/p1dmln/dFkhldVYU56noWbc7iqZwixQd6tmFNF\nUZSLo4L+aaTZjCl1Hd5JYxCaU8WTnp1Cqd3MqIB4FucHUlplYaYackFRlHZGBf3TVG3fjt1oRH9a\nff66TW8gpGTYmOeZv+4w8REGhsb4t1IuFUVRLo0K+qcxrk5GuLnhlZh4amVBOuvKD9DX1Z8dpaEc\nKqpkxqhY1RlLUZR2RwX9BqSUmJKT8UpMROPpWb++ZOUz7HZzZWT3m3g/9RDhvh5c0ye0FXOqKIpy\naVTQb6D24EEsubmNm2oeSmHD8c1IIQj1TGTL4RKmDo9Gp1VFpyhK+6MiVwOm5BQAvJOSHCvsdlj5\nF9YZAvF382P1Tle83XTcPjSy1fKoKIpyOZoU9IUQk4QQ+4UQmUKIp8+yPUoI8YsQIk0IkSKEiKhb\n318IsVEIkV637XZnfwFnMq1ejXufPriEBDtW7FmM7Xga6z09GBA0jBV7CrhjSCQ+av5bRVHaqQsG\nfSGEFngHmAzEAXcKIeJOS/Y68ImUMh6YB7xSt74KuE9K2RuYBLwphPB1VuadyVpURHVa2qmxdiw1\n8Ms80jv1psxWTVV5NwCmjohuvUwqiqJcpqbc6Q8FMqWUh6SUZmARcONpaeKA1XXLySe3SykPSCkP\n1i0fAwqBIGdk3NlMa9aAlOjHjXOs2PIelB9lXbeRaISGjbsDmNwnlAg/z/MfSFEUpQ1rStAPB442\n+Jxbt66hXcCUuuWbAb0QIqBhAiHEUMAVyLq0rDYv4+pkdGFhuPXoAVUlkPo6dJ1AauVRQly7Yax2\nY6aaGUtRlHZOd+EkTTIbeFsIMRVYC+QBtpMbhRBhwKfA/VJK++k7CyFmAbMAQkJCSElJueSMmEym\ni9/fbCY4NZXqxETWrFlDl8yPiKgxstpnHOnF/0FTOp7ufhpKs3aS0iYvWWd3SWVxBVPl0Zgqj1M6\nUlk0JejnAQ2bq0TUratXV3UzBUAI4Q3cIqUsq/vsA3wPPCOl3HS2E0gp3wPeAxg8eLBMOtl65hKk\npKRwsfsbU1LINZvpcc89ePeJgNQVMOAuqnpHItdJKsp68NqtA0jq3b7a5l9KWVzJVHk0psrjlI5U\nFk2p3tkKdBNCxAghXIE7gG8bJhBCBAohTh5rDjC/br0rsAzHQ97Fzsu2c5mSU9B4euKZMBRWvwhC\nC0lzSc1NRWvXE+nVlfG9Qlo7m4qiKJftgkFfSmkFHgZ+AjKAr6SU6UKIeUKIG+qSJQH7hRAHgBDg\npbr1twGjgalCiJ11r/7O/hKXQ9rtjl64o0ahKUqH3V9D4kPY9KGszV1PTUU3ZozsgkajhlxQFKX9\na1KdvpRyBbDitHXPNlheDJxxJy+lXAgsvMw8Nqua9L1YCwsdHbJW/gU8A2DEH9ldtJtKawWuljh+\nM0h1xlIU5crQ4XvkmpKTQaPBO9IOR1JhzNPgbmD5wWSkFNze+yo8XNX8t4qiXBk6fNA3Jifj0b8/\nus2vgX8sDJoKwE+HU5A1nZk5sk/rZlBRFMWJOnTQt+TnU5uRgb6HL5zIgKueA50rWcX5lNkO0d1n\nKMF699bOpqIoitN06KBvTE4GwNv6C0QMgThHR+O3NiwHYObgya2WN0VRlObgrM5Z7ZJpdTKuwT64\navbBhI9ACGqtNtbkpqLzMDCp26DWzqKiKIpTddg7fZupkqrNm/EOLEL0ug6iHDNlffPrUWxu+xgc\nPAyN6LDFoyjKFarDRrXK9euRFgveYSYY/1fAMXPWfzalILTV3NJrfKvmT1EUpTl02KBv+vF/aFzt\neE68EwIdwyavyywiz7wDgYbETokXOIKiKEr70yGDvrTZMK1Zi3e4FXHV3Pr176cext3nIP2C+mFw\nM7RiDhVFUZpHhwz61Su/wFZlRX/VBPB2zJK1/7iR1KxDSNdcRkeMauUcKoqiNI+OF/SlxPTFv0Aj\n8Zr2fP3qD1IP4W44CMAoFfQVRblCdbwmm/uWY9xXgldcV7QBjpEzC401/G/nMWJ652DRBdHDr0cr\nZ1JR2iaLxUJubi41NTWtnRWnMhgMZGRktHY2msTd3Z2IiAhcXC5tru6OFfRtFsyLn8Vc4YLfDXfW\nr/50YzYWu4Vymc6E8KsQQo2oqShnk5ubi16vJzo6+or6PzEajej1+tbOxgVJKSkuLiY3N5eYmJhL\nOkbHqt7ZvgBjegEA3uMcTTKrzTYWbspmaE8TlVYjo8JV1Y6inEtNTQ0BAQFXVMBvT4QQBAQEXNYv\nrY4T9GuNkPIqppIQ3Lp3xzXCMc3v4h25lFZZiIk8ilZoGdZpWCtnVFHaNhXwW9flln/HCfrr/4Wt\ntJiqXDPe48YCYLdL5q87THyEgazKbfQL6oePq08rZ1RRlHMpKyvj3XffbbXzT506lfDwcGprawEo\nKioiOjr6vPu0dp5P1zGCfkU+bHwbk3YU2O3oxzqC/i/7CjlcVMltwwzsK9mnWu0oSht3vgBqtVpb\nJA9arZb58+c3Ob0K+q0h5WWwWTCVdkIbGIh7374AvJ96iHBfDzx86ppqqvp8RWnTnn76abKysujf\nvz9PPPEEKSkpjBo1ihtuuIG4uLgz0v/ud79j8ODB9O7dm+eee65+/datWxk+fDj9+vVj6NChGI1G\nbDYbs2fPpk+fPsTHx/Pvf//7rHl49NFH+ec//3nWi8zf//53hgwZQnx8fP35Ts9za7vyW+8UZsCv\nC5GDZmH662r0k65GaDSk5Zax5XAJf762F+uPvU2wRzDd/bq3dm4Vpd14/rt09h6rcOox4zr58Nz1\nvc+5/dVXX2XPnj3s3LkTgJSUFHbs2MGePXvO2prlpZdewt/fH9v/t3fvUVFdeaLHv5uXCAiiohDw\ngYaIvIqXBEQSWlrR9AQTu110Ys9tnauxOyZ3vLmxGw134iTqqGHFvvGRK0nMdNJx1CFhJctJlBCr\nAnh9gLZBBSMaMVqKYKI8DChV7PtHQQWQl1hYUOzPWizr7HPOrl9t5eepfc75HaORpKQkiouLCQwM\nJDU1ld27dzN16lRqamowGo1kZmZSXl7OiRMncHBw4Mcff+wwhnHjxjF9+nQ+/PBDnnzySXN7Tk4O\nZWVlHD16FCklKSkp5OXl3RWztdn+kX7uanAaxk+uSTTV1TFsxgzAVHLBbYgDv47y4fCVw0z3m65O\nUCnKABQTE9Pp5Yt79uwhMjKSiIgITp8+TUlJCd9++y0+Pj5MnToVAHd3dxwcHMjNzWXp0qU4OJiO\nhUeMGNHpe65cuZI33niDpqYmc1tOTg45OTlEREQQGRnJmTNnKCsrs+AntQzbPtK/kA9n98Ev/5Xa\nr4sQQ4bgGheH/mY9n5+8yqJpE/iutoTaxlqm+063drSKMqB0dUT+ILm6unbYfuHCBTIyMigsLMTT\n0zOqVnwAABgaSURBVJOFCxda7KaygIAAwsPD2bNnj7lNSsnKlStZunRpm23Ly8st8p6WYrtH+k1N\n8OX/Bnc/ZMxz1B04gGtcHHZDh/LvBy8AsGi6P/mX83EQDsT6qEs1FaW/GzZsGLW1tT3atqamBldX\nVzw8PLh27RpffPEFAJMnT+bq1asUFhYCphuzDAYDM2fOZPv27ea5+s6md1q88sorZGRkmJeTk5PZ\nsWMHdXV1AOj1eiorK+8p5gehR0lfCDFbCPGtEOKcECKtg/XjhRBfCSGKhRA6IYRfq3X7hBA3hRB7\nLRl4t05/Alf+DjPSuV1+mUa9HrcZv6C2oZFdRy/xRKgPvsOHUqAvIHx0OMOc+v/deIoy2I0cOZL4\n+HhCQkK6PSmq0WiIiIggMDCQZ599lvj4eACcnJzYvXs3L774IhqNhpkzZ9LQ0MDixYsZN24cYWFh\naDQadu7c2WX/wcHBREZGmpdnzZrFs88+S1xcHKGhofzmN7+htrb2nmJ+IKSUXf4A9sB5YCLgBHwD\nBLXb5j+B3ze/ngF82GpdEvAksLe795JSEhUVJe+HVquVsrFByk0hUm6Ll9JokFVv/19ZMjlQ3rl2\nTb6Td16O//Ne+c2lG7KirkKG/HuIfLf43ft6z/5Kq9VaO4R+RY1HW70Zj5KSEssH0g/U1NRYO4R7\n0tHfA1Ake5Bje3KkHwOck1J+J6W8A+wC5rbbJgg40Pxa23q9lPIr4MF+tyl8F25+D7NeAzt76rRa\nnENDESNH8f7BcmImjCDMbzgHrxwEVFVNRVEGj54kfV/gUqvly81trX0DzGt+/TQwTAgx8v7Du3cO\njXXw9UaYNAMmzcBw/Tr1xcW4/SKRL05VoL9Zz+IE05n+An0Bo11GEzA8wBqhKoqiPHCWunrnZWCL\nEGIhkAfoAWNPdxZCPAc8BzBmzBh0Ol2vA/E7/x/IhmqKPFO4pdPhfPD/4SElZ4YN483Pv2GMi8Ch\nspSvKk+TfymfCNcIvv76616/X39WV1d3X2Npa9R4tNWb8fDw8OhXJyUtxWg0DqjP1dDQ0Ot/yz1J\n+npgbKtlv+Y2MynlFZqP9IUQbsCvpZQ3exqElDITyASIjo6WiYmJPd21rZvf0/T1foTmGab+wyIA\nLv1nFg0P+TAk/gkuZB7m9adCmBE7nsKKQhq+byA1OpXE8b18v35Op9PR67G0QWo82urNeJSWlg6I\nEsT3aqCUVm7h7OxMREREr/btyfROIRAghPAXQjgBvwU+a72BEGKUEKKlr5VAzwtTWNKBtaY/Z7wC\nQFNDA7cOHmRY4i94p+ACw10c+U2k6cKiAn0BDsKBR30etUqoiqIo1tBt0pdSGoAXgP1AKbBHSnla\nCPGaECKlebNE4FshxFlgDLC2ZX8hRD6mq3uShBCXhRDJFv4MJtfPQfFuLvs9CR6mxH7r8GFkQwN1\n0dPILb3G7x4dz1AnewDy9flEjonEzcmtT8JRFEXpj3p0nb6U8nMp5SNSyklSyrXNbf8ipfys+XWW\nlDKgeZvFUsrbrfZNkFJ6SSmHSin9pJT7++STjJwEC7L4ftyvzU11B7TYubjw4U8jcLSz479NGw9A\nxa0Kym6UqbtwFWUQcHN7MAd2iYmJREdHm5eLioq6nT4rLy/v9n4AS7OdO3KFgIBfYnA0/QXLpibq\ndDoc4+LZ/U0Fc8MfYvQwZwAO6k2XaqqkryiKJVVWVprv/O0JlfQtqOF0CYbKSo77hdDQ2MTihInm\ndfn6fLxdvXl4+MNWjFBRlHuVlpbG1q1bzcurV68mIyODuro6kpKSiIyMJDQ0lE8//bTbvp566imi\noqIIDg7m/fffN7fv27ePyMhINBoNSUlJgOlKp0WLFhEaGkpYWBgff/xxh32uWLGCtWvX3tVuNBpZ\nsWKFuezy9u3bzZ8nPz+f8PBwNm3adE9j0Vs2W3CtTnsA7OzYWj+GhIBRTPY2nZlvNDZy+Oph5vjP\nUVU1FeV+fJEGFSct26d3KMxZ3+nq1NRUli9fzrJlywBTFc39+/fj7OxMdnY27u7uXL9+ndjYWFJS\nUrr8Hd+xYwcjRoygvr6eqKgoFixYQFNTE0uWLCEvLw9/f39z/Z3XX38dDw8PTp40fd4bN2502Gdc\nXBzZ2dlotdo2VwO99957eHh4UFhYyO3bt4mPj2fWrFmsX7+ejIwM9u59cFVqbDbp12p13AoI4sId\nB/611VH+iaoT3Gq8paZ2FGUAioiIoLKykitXrlBVVYWnpydjx46lsbGRVatWkZeXh52dHXq9nmvX\nruHt7d1pX2+99RbZ2dmAqThaWVkZVVVVPPbYY+ZSzS3llXNzc9m1a5d5X09Pz077TU9PZ82aNWzY\nsMHclpOTQ3FxMVlZWQBUV1dTVlaGk5NT7wejl2wy6TdeucLt0lK+ip1HoPcwEgJGmdflX87HwU5V\n1VSU+9bFEXlfmj9/PllZWVRUVJCamgrARx99RFVVFceOHcPR0ZEJEyZ0WUZZp9ORm5vLoUOHcHFx\nISEhwWJll2fMmEF6ejqHDx82t0kp2bx5M8nJbS9etMbNgjY5p1/bPJCfuT7Mf5/u3+YrXr4+n6jR\nUbg6dlyDW1GU/i01NZVdu3aRlZXF/PnzAdOR8+jRo3F0dESr1XLx4sUu+6iursbT0xMXFxfOnDlj\nLrMcGxtLXl4eFy6Yyq+3TO/MnDmzzbmEzqZ3WqSnp7Nx40bzcnJyMm+//TaNjY0AnD17llu3blml\n7LJNJv26A1p+8PTmzkNjSQl/yNxecauCczfPqakdRRnAgoODqa2txdfXFx8fHwAWLFhAUVERoaGh\nfPDBBwQGBnbZx+zZszEYDEyZMoW0tDTzU7S8vLzIzMxk3rx5aDQa8zeJ9PR0bty4QUhICBqNBq1W\n22X/TzzxBF5eXublxYsXExQURGRkJCEhISxduhSDwUBYWBj29vZoNBp1Ire3REMDt44cQTd+Gr+P\nG88QB3vzunx9PqCqairKQNdyQrXFqFGjOHToUIfbtjzUpLUhQ4a0ubSydRmGOXPmMGfOnDbbu7m5\n8de//rXLmNpP1Rw7dsz82s7OjnXr1rFu3bq79jtw4MBdbX3J5o70nUpKoLGR434hLHh0fJt1BZcL\n8HH1YaLHxE72VhRFsW02l/TF34updRxKyMwEPF1/PjPecqnmdF/1AHRFUQYvm0r60mjE6eQpCr2n\nsOjxtjdeHa88zk+Gn0jwVVM7iqIMXjaV9G8UHmNowy1+ipqG/6i2V+cU6AtwtHNUVTUVRRnUbCrp\nn9izl0Zhz+O/e/KudfmX84kaE4WLo4sVIlMURekfbCbpNzVJxMF8znlPYmrw2DbrrtZd5Xz1eXWp\npqIog57NJP2Lp8vwrq7AoAm760St+VJNNZ+vKAPazZs32bZtm9Xef+HChfj6+nL7tql6/PXr15kw\nYUKX+7SPuaioiODgYO7cuQPA+fPnmThxIjU1NX0Wd2s2k/T9Qx9h7N7/YtSMmLvW5evz8XXzxd/D\n3wqRKYpiKV0lfYPB8EBisLe3Z8eOnj8csH3M0dHRPP7442RkZACwbNky1q5di7u7u8Vj7YjNJH0A\nt4cnYufe9jmXd4x3OHL1iLpUU1FsQFpaGufPnyc8PJwVK1ag0+lISEggJSWFoKCgu7b/4x//SHR0\nNMHBwbz66qvm9sLCQqZNm4ZGoyEmJoba2lqMRiMvv/wyISEhhIWFsXnz5g5jWL58OZs2berwP5k3\n3njDXD655f3axwywbt063nnnHTZu3IjBYOCZZ56xxPD0iM3dkdve8crj1Bvq1Xy+oljYhqMbOPPj\nGYv2GTgikD/H/LnT9evXr+fUqVOcOHECMN0Fe/z4cU6dOmWujNna2rVrGTFiBEajkaSkJIqLiwkM\nDCQ1NZXdu3czdepUampqMBqNZGZmUl5ezokTJ3BwcDDX3Wlv3LhxTJ8+nQ8//JAnn/z5opGcnBzK\nyso4evQoUkpSUlLIy8u7K2aA4cOHk5aWxvPPP09JSUlvh6tXbD7p51/Ox9HOkRjvu6d9FEUZ+GJi\nYjpM+GCqt5+ZmYnBYODq1auUlJQghMDHx8dcb8fd3Z3a2lpyc3P5wx/+gIODKS22lFXuyMqVK5k7\ndy6/+tWvzG05OTnk5OQQEREBmMo/lJWVMW7cuA77+OKLLxgzZgwlJSVMnjy5V5+9N2w+6RfoC4ge\nE60u1VQUC+vqiPxBcnXtuGLuhQsXyMjIoLCwEE9PTxYuXGix8skBAQGEh4ezZ88ec5uUkpUrV7J0\n6dI225aXl9+1/969e6murmb//v08/fTTJCcn4+LyYHKUTc3pt6ev0/Nd9XdqakdRbMS9lCKuqanB\n1dUVDw8Prl27Zi6wNnnyZK5evWoup1xbW4vBYGDmzJls377dPFff2fROi1deecV8MhZM5ZN37Nhh\nLvCm1+uprKy8K+b6+npeeukltm7dSmhoKHPnzu3wEYt9xaaP9AsuFwCqqqai2IqRI0cSHx9PSEgI\nc+bMaTO90p5GoyEiIoLAwEDGjh1LfHw8AE5OTuzevZsXX3yR+vp6hg4dSnZ2NosXL+bs2bOEhYXh\n6OjIkiVLeOGFFzrtPzg4mMjISI4fPw7ArFmzKC0tJS4uDjBV5vzb3/7GpEmT2sTs6OjI008/bT7x\nvHr1ajQaDQsXLiQgIMBSQ9U5KWW3P8Bs4FvgHJDWwfrxwFdAMaAD/Fqt+z1Q1vzz++7eKyoqSt4P\nrVZrfv1C7gsyOStZNjU13VefA1XrsVDUeLTXm/EoKSmxfCD9QE1NjbVDuCcd/T0ARbIH+bzb6R0h\nhD2wFZgDBAHPCCHaXxuVAXwgpQwDXgP+rXnfEcCrwKNADPCqEKLzh0ta0G3jbY5UHCHBN0Fdqqko\nitKsJ3P6McA5KeV3Uso7wC5gbrttgoCWJwFoW61PBr6UUv4opbwBfInpW0OfO3btGPWGejW1oyiK\n0kpPkr4vcKnV8uXmtta+AeY1v34aGCaEGNnDfftEgb4AJzsnpnpPfRBvpyiKMiBY6kTuy8AWIcRC\nIA/QA8ae7iyEeA54DmDMmDH39YT4uro6dDod+/X7meQ0iSMFR3rd10DXMhaKiRqPtnozHh4eHg/8\nQd4PgtFoHFCfq6Ghodf/lnuS9PVA67KVfs1tZlLKKzQf6Qsh3IBfSylvCiH0QGK7fe+KVEqZCWQC\nREdHy8TExPab9JhOp+PhqIepvFjJoohFJAb1vq+BTqfTcT9jaWvUeLTVm/EoLS01P0vWlrR+Ru5A\n4OzsbL4J7F71ZHqnEAgQQvgLIZyA3wKftd5ACDFKCNHS10qgpRrRfmCWEMKz+QTurOa2PlWgN12q\nqa7PVxRFaavbpC+lNAAvYErWpcAeKeVpIcRrQoiU5s0SgW+FEGeBMcDa5n1/BF7H9B9HIfBac1uf\nytfnM3bYWMa7j+9+Y0VRbJqbm9sDeZ/ExESio6PNy0VFRd1+kyovL2fnzp3m5U8++YSkpCTzckFB\nAeHh4RatINqjO3KllJ9LKR+RUk6SUrYk9H+RUn7W/DpLShnQvM1iKeXtVvvukFI+3PzzvsUi70Sj\nbOTo1aOqqqaiKA9cZWWl+c7fnmif9OfNm8eQIUPYuXMnjY2NPP/882zbts1cD8gSbK4Mw7mGczQY\nG9TUjqLYoLS0NLZu3WpeXr16NRkZGdTV1ZGUlERkZCShoaF8+umn3fb11FNPERUVRXBwMO+///Px\n6L59+4iMjESj0ZiPuuvq6li0aBGhoaGEhYXx8ccfd9jnihUrOiypYDQaWbFihbns8vbt282fJz8/\nn/DwcDZt2gTAli1bSE9PZ/Xq1UydOpVp06b1fIB6wObKMJTUlzDEfoi6VFNR+ljFunXcLrVsaeUh\nUwLxXrWq0/WpqaksX76cZcuWAaYqmvv378fZ2Zns7Gzc3d25fv06sbGxpKSkdPltf8eOHYwYMYL6\n+nqioqJYsGABTU1NLFmyhLy8PPz9/c31d15//XU8PDw4efIkADdu3Oiwz7i4OLKzs9FqtW1ODL/3\n3nt4eHhQWFjI7du3iY+PZ9asWaxfv56MjAz27t1r3nbixImkpqayZcsWzp8/3/PB6yGbTPrR3tEM\ndRhq7VAURbGwiIgIKisruXLlClVVVXh6ejJ27FgaGxtZtWoVeXl52NnZodfruXbtGt7e3p329dZb\nb5GdnQ2YiqOVlZVRVVXFY489Zi7V3FJeOTc3l127dpn39fTsvLBAeno6a9asYcOGDea2nJwciouL\nycrKAqC6upqysjKcnJzu2t9oNPLll1/i5ubGxYsXGTVq1D2MUPdsKulfqrlEpaGSf/L9J2uHoig2\nr6sj8r40f/58srKyqKioIDU1FYCPPvqIqqoqjh07hqOjIxMmTOiyjLJOpyM3N5dDhw7h4uJCQkKC\nxcouz5gxg/T0dA4fPmxuk1KyefNmkpOT74qjvW3bthEaGsqaNWtYtmwZhw4dsuj5SZua01cPQFcU\n25eamsquXbvIyspi/vz5gOnIefTo0Tg6OqLVarl48WKXfVRXV+Pp6YmLiwtnzpwxl1mOjY0lLy+P\nCxcuAD+XV545c2abcwmdTe+0SE9PZ+PGjebl5ORk3n77bRobGwE4e/Yst27duqvsckVFBW+++SYb\nN25k9uzZ+Pr68u677/Z0aHrEppJ+gb4ALwcvxrl3/KQaRVEGvuDgYGpra/H19cXHxweABQsWUFRU\nRGhoKB988AGBgYFd9jF79mwMBgNTpkwhLS3N/BQtLy8vMjMzmTdvHhqNxvxNIj09nRs3bhASEoJG\no0Gr1XbZ/xNPPIGXl5d5efHixQQFBREZGUlISAhLly7FYDAQFhaGvb09Go2GTZs28dJLL/GnP/3J\nvO9f/vIX1q5d221t/3shTBU5+4/o6GhZVFR0z/s1GBqYvms6sS6xbJm3pQ8iG3jUHahtqfFoq7d3\n5E6ZMqVvArKigXZHbkd/D0KIY1LK6E52MbOZOf3aO7UkjUti0k+TrB2KoihKv2Uz0zteLl5seGwD\njzg/Yu1QFEVR+i2bSfqKoihK91TSVxTlnvS384CDzf2Ov0r6iqL0mLOzMz/88INK/FYipeSHH37A\n2dm5133YzIlcRVH6np+fH5cvX6aqqsraoVhUQ0PDfSXSB8nZ2Rk/P79e76+SvqIoPebo6GguUWBL\ndDpdrx9KMtCo6R1FUZRBRCV9RVGUQUQlfUVRlEGk35VhEEJUAV1XS+raKOC6hcIZ6NRYtKXGoy01\nHj+zhbEYL6X06m6jfpf075cQoqgn9ScGAzUWbanxaEuNx88G01io6R1FUZRBRCV9RVGUQcQWk36m\ntQPoR9RYtKXGoy01Hj8bNGNhc3P6iqIoSuds8UhfURRF6YTNJH0hxGwhxLdCiHNCiDRrx2NNQoix\nQgitEKJECHFaCPHP1o7J2oQQ9kKIvwsh9lo7FmsTQgwXQmQJIc4IIUqFEHHWjsmahBD/s/n35JQQ\n4j+EEAOjCE8v2UTSF0LYA1uBOUAQ8IwQIsi6UVmVAfhfUsogIBZYNsjHA+CfgVJrB9FP/B9gn5Qy\nENAwiMdFCOEL/A8gWkoZAtgDv7VuVH3LJpI+EAOck1J+J6W8A+wC5lo5JquRUl6VUh5vfl2L6Zfa\n17pRWY8Qwg/4FfCutWOxNiGEB/AY8B6AlPKOlPKmdaOyOgdgqBDCAXABrlg5nj5lK0nfF7jUavky\ngzjJtSaEmABEAEesG4lV/QX4E9Bk7UD6AX+gCni/ebrrXSGEq7WDshYppR7IAL4HrgLVUsoc60bV\nt2wl6SsdEEK4AR8Dy6WUNdaOxxqEEP8AVEopj1k7ln7CAYgE3pZSRgC3gEF7DkwI4YlpVsAfeAhw\nFUL8zrpR9S1bSfp6YGyrZb/mtkFLCOGIKeF/JKX8xNrxWFE8kCKEKMc07TdDCPE364ZkVZeBy1LK\nlm9+WZj+ExisfglckFJWSSkbgU+AaVaOqU/ZStIvBAKEEP5CCCdMJ2I+s3JMViOEEJjmbEullG9a\nOx5rklKulFL6SSknYPp3cUBKadNHcl2RUlYAl4QQk5ubkoASK4Zkbd8DsUIIl+bfmyRs/MS2TTw5\nS0ppEEK8AOzHdPZ9h5TytJXDsqZ44B+Bk0KIE81tq6SUn1sxJqX/eBH4qPkA6TtgkZXjsRop5REh\nRBZwHNNVb3/Hxu/OVXfkKoqiDCK2Mr2jKIqi9IBK+oqiKIOISvqKoiiDiEr6iqIog4hK+oqiKIOI\nSvqKoiiDiEr6iqIog4hK+oqiKIPI/wesT9I7WBv0pgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1254b673c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=32,shuffle=True):\n",
    "        train(network,x_batch,y_batch)\n",
    "        train(networkX,x_batch,y_batch)\n",
    "    \n",
    "    train_log.append(np.mean(predict(network,X_train)==y_train))\n",
    "    val_log.append(np.mean(predict(network,X_val)==y_val))\n",
    "    \n",
    "    train_logX.append(np.mean(predict(networkX,X_train)==y_train))\n",
    "    val_logX.append(np.mean(predict(networkX,X_val)==y_val))\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"Epoch\",epoch)\n",
    "    print(\"Train acc: Net:{} NetX:{}\".format(train_log[-1],train_logX[-1]))\n",
    "    print(\"Val acc:Net:{} NetX:{}\".format(val_log[-1],val_logX[-1]))\n",
    "    plt.plot(train_log,label='tr acc Net')\n",
    "    plt.plot(val_log,label='val acc Net')\n",
    "    plt.plot(train_logX,label='tr acc NetX')\n",
    "    plt.plot(val_logX,label='val acc NetX')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hence, We can conclude that Xavier Initialisation of weights helps the model to converge faster and reduces the chances of exploding/vanishing gradients.\n",
    "\n",
    "Further the Dropout of 0.2 in the last layers helps to reduce the model Variance without that dropout the model suffers from large variance, ie the difference between train accuracy and validation accuracy is high.\n",
    "Thus Dropout helps to reduce Model overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
